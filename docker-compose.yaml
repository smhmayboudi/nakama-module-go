# https://heroiclabs.com/docs/nakama/getting-started/install/docker/

services:

  cockroach:
    container_name: cockroach
    command:
      - start-single-node
      - --http-addr=0.0.0.0:8080
      - --insecure
      - --listen-addr=0.0.0.0:26257
      # - --sql-addr=0.0.0.0:26257
      - --store=attrs=ssd,path=/var/lib/cockroach/
    expose:
      - 8080
      - 26257
    healthcheck:
      interval: 10s
      retries: 5
      start_period: 5s
      test: curl -f http://cockroach:8080/health
      timeout: 5s
    image: cockroachdb/cockroach:v21.2.11
    labels:
      namespace: cockroach
    ports:
      - 8080:8080
      # - 26257:26257
    restart: "no"
    volumes:
      - cockroach:/var/lib/cockroach

  jaeger:
    container_name: jaeger
    environment:
      - LOG_LEVEL=debug
      - COLLECTOR_ZIPKIN_ALLOWED_HEADERS=*
      - COLLECTOR_ZIPKIN_ALLOWED_ORIGINS=*
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
    expose:
      - 5775/udp # accept zipkin.thrift over compact thrift protocol (deprecated, used by legacy clients only)
      - 6831/udp # accept jaeger.thrift over compact thrift protocol
      - 6832/udp # accept jaeger.thrift over binary thrift protocol
      - 5778 # serve configs
      - 16686 # serve frontend
      - 14268 # accept jaeger.thrift directly from clients
      - 14269 # admin port: health check at / and metrics at /metrics
      - 14250 # accept model.proto
      - 9411 # Zipkin compatible endpoint (optional)
    healthcheck:
      interval: 10s
      retries: 5
      start_period: 5s
      test: wget --no-verbose --tries=1 --spider http://jaeger:14269
      timeout: 5s
    image: jaegertracing/all-in-one:1.34.1
    labels:
      namespace: jaeger
    ports:
      # - 5775:5775/udp
      # - 6831:6831/udp
      # - 6832:6832/udp
      # - 5778:5778
      - 16686:16686
      # - 14268:14268
      # - 14269:14269
      # - 14250:14250
      # - 9411:9411
    restart: "no"

  # materialize-cli:
  #   entrypoint:
  #     - "/bin/sh"
  #     - "-ecx"
  #     - >
  #       exec /usr/bin/psql --file=/materialize-cli.sql postgres://materialize@materialized:6875/materialize
  #   command:
  #     - --host=materialize
  #     - --no-password
  #     - --port=6875 materialize
  #     - --username=materialize
  #   container_name: materialize-cli
  #   depends_on:
  #     materialized:
  #       condition: service_healthy
  #   image: materialize/cli:v0.26.2
  #   labels:
  #     namespace: materialize-cli
  #   restart: "no"
  #   volumes:
  #     - ./docker/materialize-cli.sql:/materialize-cli.sql:ro

  # # https://materialize.com/docs/cli/
  # materialized:
  #   command:
  #     - --data-directory=/data
  #     - --disable-telemetry
  #     - --introspection-frequency=1s
  #     - --listen-addr=0.0.0.0:6875
  #     - --log-filter=info
  #     - --logical-compaction-window=1s
  #     - --metrics-scraping-interval=30s
  #     - --workers=1
  #   container_name: materialized
  #   depends_on:
  #     redpanda:
  #       condition: service_healthy
  #   expose:
  #     - 6875
  #   healthcheck:
  #     interval: 10s
  #     retries: 5
  #     start_period: 5s
  #     test: curl -f http://materialized:6875
  #     timeout: 5s
  #   image: materialize/materialized:v0.26.2
  #   labels:
  #     namespace: materialized
  #   # ports:
  #   #   - 6875:6875
  #   restart: "no"
  #   volumes:
  #     # - ./docker/materialized.yaml:/etc/materialized/config.yaml:ro
  #     - materialized:/mzdata

  nakama:
    container_name: nakama
    depends_on:
      cockroach:
        condition: service_healthy
      jaeger:
        condition: service_healthy
      nakama-pluginbuilder:
        condition: service_completed_successfully
      otelcol:
        condition: service_started
      pgadmin4:
        condition: service_healthy
      redpanda:
        condition: service_healthy
    entrypoint:
      - "/bin/sh"
      - "-ecx"
      - >
        /nakama/nakama migrate up --database.address root@cockroach:26257 &&
        exec /nakama/nakama --config=/etc/nakama/config.yaml
    env_file:
      - ./.env
    expose:
      - 7348 # gRPC API embedded developer
      - 7349 # gRPC API
      - 7350 # HTTP API
      - 7351 # HTTP API embedded developer
      - 9100 # Prometheus
    healthcheck:
      interval: 10s
      retries: 5
      start_period: 5s
      test: curl -f http://nakama:7350
      timeout: 5s
    image: heroiclabs/nakama:3.12.0
    labels:
      namespace: nakama
    ports:
      - 7348:7348
      - 7349:7349
      - 7350:7350
      - 7351:7351
      # - 9100:9100
    restart: "no"
    volumes:
      - ./build:/nakama/data/modules:ro
      - ./docker/nakama.yaml:/etc/nakama/config.yaml:ro
      - nakama:/nakama/data

  nakama-pluginbuilder:
    container_name: nakama-pluginbuilder
    entrypoint: ./script/nakama-pluginbuilder.sh true
    image: heroiclabs/nakama-pluginbuilder:3.12.0
    labels:
      namespace: nakama-pluginbuilder
    restart: "no"
    volumes:
      - ./:/workspace
    working_dir: /workspace

  otelcol:
    command:
      - --config=/etc/otelcol/config.yaml
    container_name: otelcol
    expose:
      - 4317
      - 4318
      - 8888
      - 14268
      - 13133
    # healthcheck:
    #   interval: 10s
    #   retries: 5
    #   start_period: 5s
    #   test: curl -f http://otelcol:13133
    #   timeout: 5s
    image: otel/opentelemetry-collector:0.52.0
    labels:
      namespace: otelcol
    ports:
      # - 4317:4317
      - 4318:4318
      # - 8888:8888
      # - 14268:14268
      # - 13133:13133
    restart: unless-stopped
    volumes:
      - ./docker/otelcol.yaml:/etc/otelcol/config.yaml

  # https://www.pgadmin.org/docs/pgadmin4/latest/container_deployment.html
  pgadmin4:
    container_name: pgadmin4
    depends_on:
      cockroach:
        condition: service_healthy
    environment:
      - PGADMIN_DEFAULT_EMAIL=pgadmin4@domain.com
      - PGADMIN_DEFAULT_PASSWORD=SuperSecret
      - PGADMIN_LISTEN_ADDRESS=0.0.0.0
      - PGADMIN_LISTEN_PORT=5050
    expose:
      - 5050
    healthcheck:
      interval: 10s
      retries: 5
      start_period: 5s
      test: wget --no-verbose --spider --tries=1 http://pgadmin4:5050
      timeout: 5s
    image: dpage/pgadmin4:6.9
    labels:
      namespace: pgadmin4
    ports:
      - 5050:5050
    restart: "no"
    volumes:
      - ./docker/pgadmin4.json:/pgadmin4/servers.json:ro
      - ./docker/pgadmin4.pass:/pgadmin4/pass:ro

  # https://docs.redpanda.com/docs/cluster-administration/configuration/
  redpanda:
    command:
      - redpanda
      - start
      # - --redpanda-cfg=/etc/redpanda/config.yaml
      - --advertise-kafka-addr=PLAINTEXT://redpanda:29092,OUTSIDE://localhost:9092
      - --advertise-pandaproxy-addr=localhost:8082
      - --check=false
      - --default-log-level=info
      - --kafka-addr=PLAINTEXT://0.0.0.0:29092,OUTSIDE://0.0.0.0:9092
      - --memory=1G
      - --node-id=0
      - --overprovisioned
      - --pandaproxy-addr=0.0.0.0:8082
      - --reserve-memory=0M
      - --set redpanda.enable_idempotence=true
      - --set redpanda.enable_transactions=true
      - --smp=1
    container_name: redpanda
    expose:
      - 8081 # schema registry api
      - 8082 # panda proxy api
      - 9092 # kafka api
      - 29092 # CONNECT FROM APPS
      - 9644 # admin api
    healthcheck:
      interval: 10s
      retries: 5
      start_period: 5s
      test: curl -f http://redpanda:8081/schemas/types
      timeout: 5s
    image: vectorized/redpanda:v22.1.3
    labels:
      namespace: redpanda
    # ports:
    #   - 8081:8081
    #   - 8082:8082
    #   - 9092:9092
    #   - 29092:29092
    #   - 9644:9644
    restart: "no"
    volumes:
      # - ./docker/redpanda.yaml:/etc/redpanda/config.yaml:ro
      - redpanda:/var/lib/redpanda/data

  # https://docs.redpanda.com/docs/cluster-administration/configuration/
  # vector:
  #   command:
  #     - --color=never
  #     - --config=/etc/vector/config.yaml
  #     - --log-format=json
  #     - --require-healthy=true
  #   container_name: vector
  #   depends_on:
  #     redpanda:
  #       condition: service_healthy
  #   expose:
  #     - 8686
  #   healthcheck:
  #     interval: 10s
  #     retries: 5
  #     start_period: 5s
  #     test: curl -f http://vector:8686/health
  #     timeout: 5s
  #   image: timberio/vector:0.21.2-debian
  #   labels:
  #     namespace: vector
  #   # ports:
  #   #   - 8686:8686
  #   restart: "no"
  #   volumes:
  #     - ./docker/vector.yaml:/etc/vector/config.yaml:ro
  #     - vector:/var/lib/vector

volumes:
  cockroach:
  # materialized:
  nakama:
  redpanda:
  # vector:
